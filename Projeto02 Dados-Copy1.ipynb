{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 13/Set até às 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "Até o dia 06 de Setembro às 23:59, o notebook e o xlsx devem estar no Github com as seguintes evidências: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste já classificado.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy e textblob\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@sabrina49834572***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'RedBull2'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t2])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t2:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.[OK]<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.[OK]\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "readerTrain = pd.read_excel('{0}.xlsx'.format(produto))\n",
    "readerTest = pd.read_excel('{0}.xlsx'.format(produto),sheetname = 'Teste')\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in range(0,t):\n",
    "    train.append([readerTrain['Treinamento'][i], readerTrain['Util'][i]])\n",
    "\n",
    "for i in range(0,n-t):\n",
    "    test.append([readerTest['Teste'][i],readerTest['Util'][i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(n):\n",
    "    total = 1\n",
    "    for i in range(0, len(n)):\n",
    "        total *= n[i]\n",
    "    return total\n",
    "\n",
    "def Maior(nlist):\n",
    "    ValueMaior = nlist[0]\n",
    "    IndexMaior = 0\n",
    "    for i in range(len(nlist)):\n",
    "        if nlist[i] > ValueMaior: \n",
    "            ValueMaior = nlist[i]\n",
    "            IndexMaior = i\n",
    "    return IndexMaior\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.Freq0 = 0\n",
    "        self.Freq1 = 0\n",
    "        self.Freq2 = 0\n",
    "        self.Freq3 = 0\n",
    "        self.Freq4 = 0\n",
    "        self.WordFreqList = [[\"redbull\",0,0,0,0,0]]\n",
    "                            #[Palavra, Freq0, Freq1, Freq2, Freq3, Freq4]\n",
    "        self.TotalWord = [1,0,0,0,0,0]\n",
    "                            #Palavra, Freq0, Freq1, Freq2, Freq3, Freq4\n",
    "        \n",
    "    def train(self,train):\n",
    "        for tweet in train:\n",
    "            if tweet[1] == 0: self.Freq0 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 1: self.Freq1 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 2: self.Freq2 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 3: self.Freq3 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 4: self.Freq4 +=1\n",
    "            tweet[0] = self.normalizeTweet(tweet[0])#0 = Coluna Treinamento\n",
    "            WordList = tweet[0].split(' ') #0 = Coluna Treinamento\n",
    "            for word in WordList:\n",
    "                onList = False\n",
    "                for freq in self.WordFreqList:\n",
    "                    if word == freq[0]:\n",
    "                        onList = True\n",
    "                        if tweet[1] == 0: \n",
    "                            freq[1]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[1]+=1\n",
    "                        elif tweet[1] == 1: \n",
    "                            freq[2]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[2]+=1\n",
    "                        elif tweet[1] == 2: \n",
    "                            freq[3]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[3]+=1\n",
    "                        elif tweet[1] == 3: \n",
    "                            freq[4]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[4]+=1\n",
    "                        elif tweet[1] == 4: \n",
    "                            freq[5]+=1\n",
    "                            self.TotalWord[5]+=1\n",
    "                \n",
    "                if not onList:\n",
    "                    self.TotalWord[0]+=1\n",
    "                    if tweet[1] == 0: self.WordFreqList.append([word,1,0,0,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 1: self.WordFreqList.append([word,0,1,0,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 2: self.WordFreqList.append([word,0,0,1,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 3: self.WordFreqList.append([word,0,0,0,1,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 4: self.WordFreqList.append([word,0,0,0,0,1])\n",
    "        return 0\n",
    "    \n",
    "    def test(self, test):\n",
    "        acertoTotal = 0 \n",
    "        erroTotal = 0\n",
    "        acerto0 = 0\n",
    "        erro0 = 0\n",
    "        acerto1 = 0\n",
    "        erro1 = 0\n",
    "        acerto2 = 0\n",
    "        erro2 = 0\n",
    "        acerto3 = 0\n",
    "        erro3 = 0\n",
    "        acerto4 = 0\n",
    "        erro4 = 0\n",
    "        for tweet in test:\n",
    "            if self.analyze(tweet)==tweet[1]:\n",
    "                acertoTotal+=1\n",
    "                if tweet[1] == 0: acerto0 +=1\n",
    "                elif tweet[1] == 1: acerto1 +=1\n",
    "                elif tweet[1] == 2: acerto2 +=1\n",
    "                elif tweet[1] == 3: acerto3 +=1\n",
    "                elif tweet[1] == 4: acerto4 +=1\n",
    "            else:\n",
    "                erroTotal +=1\n",
    "                if tweet[1] == 0: erro0 +=1\n",
    "                elif tweet[1] == 1: erro1 +=1\n",
    "                elif tweet[1] == 2: erro2 +=1\n",
    "                elif tweet[1] == 3: erro3 +=1\n",
    "                elif tweet[1] == 4: erro4 +=1\n",
    "\n",
    "        print(\"0 Falso: \" + str((erro0 /(n-t))*100)+\"%\")\n",
    "        print(\"0 Verdadeiro: \" + str((acerto0 /(n-t))*100)+\"%\")\n",
    "        print()\n",
    "        print(\"1 Falso: \" + str((erro1 /(n-t))*100)+\"%\")\n",
    "        print(\"1 Verdadeiro: \" + str((acerto1 /(n-t))*100)+\"%\")\n",
    "        print()\n",
    "        print(\"2 Falso: \" + str((erro2 /(n-t))*100)+\"%\")\n",
    "        print(\"2 Verdadeiro: \" + str((acerto2 /(n-t))*100)+\"%\")\n",
    "        print()\n",
    "        print(\"3 Falso: \" + str((erro3 /(n-t))*100)+\"%\")\n",
    "        print(\"3 Verdadeiro: \" + str((acerto3 /(n-t))*100)+\"%\")\n",
    "        print()\n",
    "        print(\"4 Falso: \" + str((erro4 /(n-t))*100)+\"%\")\n",
    "        print(\"4 Verdadeiro: \" + str((acerto4 /(n-t))*100)+\"%\")\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        print(\"Acerto: \" + str(((acerto0 + acerto1 + acerto2 + acerto3 + acerto4)/(n-t))*100)+\"%\")\n",
    "        print(\"Erro: \"  + str(((erro0 + erro1 + erro2 + erro3 + erro4)/(n-t))*100)+\"%\")\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "        print(\"Total: \" + str(((erro0 + erro1 + erro2 + erro3 + erro4 + acerto0 + acerto1 + acerto2 + acerto3 + acerto4)/(n-t))*100)+\"%\")\n",
    "             \n",
    "    \n",
    "    def analyze(self,tweet):\n",
    "        \n",
    "        tweet[0] = self.normalizeTweet(tweet[0])#0 = Coluna Treinamento\n",
    "        WordList = tweet[0].split(' ') #0 = Coluna Treinamento\n",
    "        relevancia = [] #acho que nao ta sendo usado\n",
    "        probWord = []\n",
    "        for word in WordList:\n",
    "            onList = False\n",
    "            for freq in self.WordFreqList:\n",
    "                if word == freq[0]:\n",
    "                    onList = True\n",
    "                    prob0 = (freq[1]+1)/(self.TotalWord[1]+self.TotalWord[0])\n",
    "                    prob1 = (freq[2]+1)/(self.TotalWord[2]+self.TotalWord[0])\n",
    "                    prob2 = (freq[3]+1)/(self.TotalWord[3]+self.TotalWord[0])\n",
    "                    prob3 = (freq[4]+1)/(self.TotalWord[4]+self.TotalWord[0])\n",
    "                    prob4 = (freq[5]+1)/(self.TotalWord[5]+self.TotalWord[0])\n",
    "                    probTotal = (freq[1]+freq[2]+freq[3]+freq[4]+freq[5] +1)/self.TotalWord[0]\n",
    "                    probWord.append([probTotal, prob0, prob1, prob2, prob3, prob4])\n",
    "                    \n",
    "            if not onList:\n",
    "                probWord.append([1/self.TotalWord[0], 1/(self.TotalWord[1]+self.TotalWord[0]), 1/(self.TotalWord[2]+self.TotalWord[0]), 1/(self.TotalWord[3]+self.TotalWord[0]), 1/(self.TotalWord[4]+self.TotalWord[0]), 1/(self.TotalWord[5]+self.TotalWord[0])])\n",
    "        try:pW1 = multiply(probWord[:][1])\n",
    "        except:pW1 = 0\n",
    "        try:pW2 = multiply(probWord[:][2])\n",
    "        except:pW2 = 0\n",
    "        try:pW3 = multiply(probWord[:][3])\n",
    "        except:pW3 = 0\n",
    "        try:pW4 = multiply(probWord[:][4])\n",
    "        except:pW4 = 0\n",
    "        try:pW5 = multiply(probWord[:][5])\n",
    "        except:pW5 = 0\n",
    "        \n",
    "        probTweet = [pW1,pW2,pW3,pW4,pW5]\n",
    "        return Maior(probTweet)  \n",
    " \n",
    "    def normalizeTweet(self,tweet):\n",
    "        tweet.lower()\n",
    "        tweet = tweet.replace(',',' ')\n",
    "        tweet = tweet.replace('!',' ')\n",
    "        tweet = tweet.replace('$',' ')\n",
    "        tweet = tweet.replace('%',' ')\n",
    "        tweet = tweet.replace('&',' ')\n",
    "        tweet = tweet.replace('*',' ')\n",
    "        tweet = tweet.replace('(',' ')\n",
    "        tweet = tweet.replace(')',' ')\n",
    "        tweet = tweet.replace('-',' ')\n",
    "        tweet = tweet.replace('+',' ')\n",
    "        tweet = tweet.replace('=',' ')\n",
    "        tweet = tweet.replace('_',' ')\n",
    "        tweet = tweet.replace('.',' ')\n",
    "        tweet = tweet.replace(':',' ')\n",
    "        tweet = tweet.replace(';',' ')\n",
    "        tweet = tweet.replace('?',' ')\n",
    "        tweet = tweet.replace('/',' ')\n",
    "        tweet = tweet.replace('\\n',' ')\n",
    "        for i in range(0,4): tweet = tweet.replace('  ',' ')\n",
    "        return tweet\n",
    "                              \n",
    "    def show(self):\n",
    "        print(\"SIMs: \" + str(self.YesFreq))\n",
    "        print(\"NÃOs: \" + str(self.NoFreq))\n",
    "        print(\"TOTAL: \" + str(self.YesFreq+self.NoFreq))\n",
    "    \n",
    "    def showAll(self):\n",
    "        print(self.WordFreqList)\n",
    "        print()\n",
    "        print(\"SIMs: \" + str(self.YesFreq))\n",
    "        print(\"NÃOs: \" + str(self.NoFreq))\n",
    "        print(\"TOTAL: \" + str(self.YesFreq+self.NoFreq))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Falso: 13.5%\n",
      "0 Verdadeiro: 2.0%\n",
      "\n",
      "1 Falso: 16.5%\n",
      "1 Verdadeiro: 2.5%\n",
      "\n",
      "2 Falso: 52.5%\n",
      "2 Verdadeiro: 3.5000000000000004%\n",
      "\n",
      "3 Falso: 8.0%\n",
      "3 Verdadeiro: 1.5%\n",
      "\n",
      "4 Falso: 0.0%\n",
      "4 Verdadeiro: 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Acerto: 9.5%\n",
      "Erro: 90.5%\n",
      "\n",
      "\n",
      "\n",
      "Total: 100.0%\n"
     ]
    }
   ],
   "source": [
    "Classificador = NaiveBayes()\n",
    "Classificador.train(train)\n",
    "Classificador.test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante.[  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.[OK]<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.[OK]<br />\n",
    "Explique como são tratadas as mensagens com duplanegação e sarcasmo.[OK]<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?[OK]<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.[ ]\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.[ ]\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).[OK]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O nosso Classificador Naive-Bayes analisa propabilidade de um tweet ser relevante baseado nas palavras usadas nele. Para conhecer a probalidade de relevancia de uma palavra fornecemos um primeiro grupo de tweet para treina-lo.\n",
    "Tivemos um percentual de analises corretas bem alta, porem o numero de Positivos Verdadeiros foi bastante baixo, isso pode estar ligada a poucos exemplos de Positivos em seu treino (Qualidade do Dataframe de Treino) e já que não existe uma analise completa do tweet, nosso clasificador não reconhece contexto, sarcasmo, duplas negações ou qualquer outro aspecto da frase que não seja a probalidade de suas palavras tornararem o proprio tweet relevante, isso faz com que o classificador cometa diverssos erros, já que podemos usar certas palavras em ambos os casos (Tweets relevantes e Irrelevantes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Em nossas proximas iterações, para podermos aprimorar nosso Classificador e sem alterar o tipo dele (Naive-Bayes), vamos por exemplo:\n",
    "    \n",
    "* Ao se deparar com o Tweet: \"Eu gosto de beber Redbull sextas a noite\", alem de analisar e registrar cada uma das palavras nossa classificador passará a analisar tambem fragmentos do tweet, como: \"Eu gosto de\", \"beber Redbull\" e \"sextas a noite\"<br /> \n",
    "* Passar a não registrar artigos de ligação, como: \"de\", \"do\", \"dos\", \"da\", \"das\", etc.<br />\n",
    "* Fornecer ao Classificador um grupo de regras para transformar abreviações em sua versão completa e corrigir erros de escrita, para que dessa forma não registre duas palavras iguais como duas diferentes, tal como: \"vc\" e \"você\", aumentando a qualidade do treinamento e de analise do Classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
