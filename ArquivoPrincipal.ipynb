{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Classificador Automático de Sentimento\n",
    "\n",
    "Baseado no metodo Naive-Bayes, ao longo deste projeto desenvolvemos um classificador de Tweet que opera entre 5 categorias: Muito Relevante, Relevante, Irrelevante, Muito Irrelevante e Memes.<br><br/>\n",
    "Veja a seguir como fizemos isso e nossas conclusões\n",
    "\n",
    "___\n",
    "## Informações do Projeto\n",
    "\n",
    "Grupo: Sabrina Machado e Phelipe Müller<br /><br />\n",
    "GitHub: https://github.com/PhelipeMuller/Classificador-Bayes\n",
    "\n",
    "Conta no Twitter:***@sabrina49834572***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Classificamos varias mensagens vindas do Twitter para usar em nosso Classificador e as separamos em dois grupo, treino e teste\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Pegamos os Tweets dos arquivos de Excel, já classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "produto = 'RedBull2'\n",
    "n = 500\n",
    "t = 300\n",
    "\n",
    "readerTrain = pd.read_excel('{0}.xlsx'.format(produto))\n",
    "readerTest = pd.read_excel('{0}.xlsx'.format(produto),sheetname = 'Teste')\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in range(0,t):\n",
    "    train.append([readerTrain['Treinamento'][i], readerTrain['Util'][i]])\n",
    "\n",
    "for i in range(0,n-t):\n",
    "    test.append([readerTest['Teste'][i],readerTest['Util'][i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos duas funções que vamos utilizar ao longo do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply(n):\n",
    "    total = 1\n",
    "    for i in range(0, len(n)):\n",
    "        total *= n[i]\n",
    "    return total\n",
    "\n",
    "def Maior(nlist):\n",
    "    ValueMaior = nlist[0]\n",
    "    IndexMaior = 0\n",
    "    for i in range(len(nlist)):\n",
    "        if nlist[i] > ValueMaior: \n",
    "            ValueMaior = nlist[i]\n",
    "            IndexMaior = i\n",
    "    return IndexMaior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E uma Classe com os seguintes metodos:\n",
    "train: Que recebe uma lista de Tweets ja analisados e treina nosso classificador\n",
    "analyze: Que baseado no treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.trained = False\n",
    "        self.Freq0 = 0\n",
    "        self.Freq1 = 0\n",
    "        self.Freq2 = 0\n",
    "        self.Freq3 = 0\n",
    "        self.Freq4 = 0\n",
    "        self.WordFreqList = [[\"redbull\",0,0,0,0,0]]\n",
    "                            #[Palavra, Freq0, Freq1, Freq2, Freq3, Freq4]\n",
    "        self.TotalWord = [1,0,0,0,0,0]\n",
    "                            #Palavra, Freq0, Freq1, Freq2, Freq3, Freq4\n",
    "        self.CatProb=[0,0,0,0,0]\n",
    "        \n",
    "    def train(self,train):\n",
    "        for tweet in train:\n",
    "            if tweet[1] == 0: self.Freq0 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 1: self.Freq1 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 2: self.Freq2 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 3: self.Freq3 +=1 #1 = Coluna Util\n",
    "            elif tweet[1] == 4: self.Freq4 +=1\n",
    "            tweet[0] = self.normalizeTweet(tweet[0])#0 = Coluna Treinamento\n",
    "            WordList = tweet[0].split(' ') #0 = Coluna Treinamento\n",
    "            for word in WordList:\n",
    "                onList = False\n",
    "                for freq in self.WordFreqList:\n",
    "                    if word == freq[0]:\n",
    "                        onList = True\n",
    "                        if tweet[1] == 0: \n",
    "                            freq[1]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[1]+=1\n",
    "                        elif tweet[1] == 1: \n",
    "                            freq[2]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[2]+=1\n",
    "                        elif tweet[1] == 2: \n",
    "                            freq[3]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[3]+=1\n",
    "                        elif tweet[1] == 3: \n",
    "                            freq[4]+=1 #1 = Coluna Util\n",
    "                            self.TotalWord[4]+=1\n",
    "                        elif tweet[1] == 4: \n",
    "                            freq[5]+=1\n",
    "                            self.TotalWord[5]+=1    \n",
    "                if not onList:\n",
    "                    self.TotalWord[0]+=1\n",
    "                    if tweet[1] == 0: self.WordFreqList.append([word,1,0,0,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 1: self.WordFreqList.append([word,0,1,0,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 2: self.WordFreqList.append([word,0,0,1,0,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 3: self.WordFreqList.append([word,0,0,0,1,0]) #1 - Coluna Util\n",
    "                    elif tweet[1] == 4: self.WordFreqList.append([word,0,0,0,0,1])\n",
    "        self.trained = True\n",
    "        self.CatProb[0] = self.Freq0/300\n",
    "        self.CatProb[1] = self.Freq1/300\n",
    "        self.CatProb[2] = self.Freq2/300\n",
    "        self.CatProb[3] = self.Freq3/300\n",
    "        self.CatProb[4] = self.Freq4/300\n",
    "        return 0\n",
    "    \n",
    "    def test(self, test):\n",
    "        if self.trained:\n",
    "            acertoTotal = 0 \n",
    "            erroTotal = 0\n",
    "            acerto0 = 0\n",
    "            erro0 = 0\n",
    "            acerto1 = 0\n",
    "            erro1 = 0\n",
    "            acerto2 = 0\n",
    "            erro2 = 0\n",
    "            acerto3 = 0\n",
    "            erro3 = 0\n",
    "            acerto4 = 0\n",
    "            erro4 = 0\n",
    "            for tweet in test:\n",
    "                if self.analyze(tweet)==tweet[1]:\n",
    "                    acertoTotal+=1\n",
    "                    if tweet[1] == 0: acerto0 +=1\n",
    "                    elif tweet[1] == 1: acerto1 +=1\n",
    "                    elif tweet[1] == 2: acerto2 +=1\n",
    "                    elif tweet[1] == 3: acerto3 +=1\n",
    "                    elif tweet[1] == 4: acerto4 +=1\n",
    "                else:\n",
    "                    erroTotal +=1\n",
    "                    if tweet[1] == 0: erro0 +=1\n",
    "                    elif tweet[1] == 1: erro1 +=1\n",
    "                    elif tweet[1] == 2: erro2 +=1\n",
    "                    elif tweet[1] == 3: erro3 +=1\n",
    "                    elif tweet[1] == 4: erro4 +=1\n",
    "\n",
    "            print(\"Muito Irrelevante Falso: \" + str((erro0 /(n-t))*100)+\"%\")\n",
    "            print(\"Muito Irrelevante Verdadeiro: \" + str((acerto0 /(n-t))*100)+\"%\")\n",
    "            print()\n",
    "            print(\"Irrelevante Falso: \" + str((erro1 /(n-t))*100)+\"%\")\n",
    "            print(\"Irrelevante Verdadeiro: \" + str((acerto1 /(n-t))*100)+\"%\")\n",
    "            print()\n",
    "            print(\"Meme Falso: \" + str((erro2 /(n-t))*100)+\"%\")\n",
    "            print(\"Meme Verdadeiro: \" + str((acerto2 /(n-t))*100)+\"%\")\n",
    "            print()\n",
    "            print(\"Relevante Falso: \" + str((erro3 /(n-t))*100)+\"%\")\n",
    "            print(\"Relevante Verdadeiro: \" + str((acerto3 /(n-t))*100)+\"%\")\n",
    "            print()\n",
    "            print(\"Muito Relevante Falso: \" + str((erro4 /(n-t))*100)+\"%\")\n",
    "            print(\"Muito Relevante Verdadeiro: \" + str((acerto4 /(n-t))*100)+\"%\")\n",
    "\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            print(\"Acerto: \" + str(((acerto0 + acerto1 + acerto2 + acerto3 + acerto4)/(n-t))*100)+\"%\")\n",
    "            print(\"Erro: \"  + str(((erro0 + erro1 + erro2 + erro3 + erro4)/(n-t))*100)+\"%\")\n",
    "\n",
    "            print()\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "            print(\"Total: \" + str(((erro0 + erro1 + erro2 + erro3 + erro4 + acerto0 + acerto1 + acerto2 + acerto3 + acerto4)/(n-t))*100)+\"%\")\n",
    "        else: print(\"Você precisa treinar seu classificador antes de tentar analisar algo\")\n",
    "    \n",
    "    def analyze(self,tweet):\n",
    "        \n",
    "        tweet[0] = self.normalizeTweet(tweet[0])#0 = Coluna Treinamento\n",
    "        WordList = tweet[0].split(' ') #0 = Coluna Treinamento\n",
    "        relevancia = [] #acho que nao ta sendo usado\n",
    "        probWord = []\n",
    "        for word in WordList:\n",
    "            onList = False\n",
    "            for freq in self.WordFreqList:\n",
    "                if word == freq[0]:\n",
    "                    onList = True\n",
    "                    prob0 = (freq[1]+1)/(self.TotalWord[1]+self.TotalWord[0])\n",
    "                    prob1 = (freq[2]+1)/(self.TotalWord[2]+self.TotalWord[0])\n",
    "                    prob2 = (freq[3]+1)/(self.TotalWord[3]+self.TotalWord[0])\n",
    "                    prob3 = (freq[4]+1)/(self.TotalWord[4]+self.TotalWord[0])\n",
    "                    prob4 = (freq[5]+1)/(self.TotalWord[5]+self.TotalWord[0])\n",
    "                    probTotal = (freq[1]+freq[2]+freq[3]+freq[4]+freq[5] +1)/self.TotalWord[0]\n",
    "                    probWord.append([probTotal, prob0, prob1, prob2, prob3, prob4])\n",
    "                    \n",
    "            if not onList:\n",
    "                probWord.append([1/self.TotalWord[0], 1/(self.TotalWord[1]+self.TotalWord[0]+1), 1/(self.TotalWord[2]+self.TotalWord[0]+1), 1/(self.TotalWord[3]+self.TotalWord[0]+1), 1/(self.TotalWord[4]+self.TotalWord[0]+1), 1/(self.TotalWord[5]+self.TotalWord[0]+1)])\n",
    "        try:pW1 = multiply(probWord[:][1])*self.CatProb[0]\n",
    "        except:pW1 = 0\n",
    "        try:pW2 = multiply(probWord[:][2])*self.CatProb[1]\n",
    "        except:pW2 = 0\n",
    "        try:pW3 = multiply(probWord[:][3])*self.CatProb[2]\n",
    "        except:pW3 = 0\n",
    "        try:pW4 = multiply(probWord[:][4])*self.CatProb[3]\n",
    "        except:pW4 = 0\n",
    "        try:pW5 = multiply(probWord[:][5])*self.CatProb[4]\n",
    "        except:pW5 = 0\n",
    "        \n",
    "        probTweet = [pW1,pW2,pW3,pW4,pW5]\n",
    "        return Maior(probTweet)  \n",
    " \n",
    "    def normalizeTweet(self,tweet):\n",
    "        tweet.lower()\n",
    "        tweet = tweet.replace(',',' ')\n",
    "        tweet = tweet.replace('!',' ')\n",
    "        tweet = tweet.replace('$',' ')\n",
    "        tweet = tweet.replace('%',' ')\n",
    "        tweet = tweet.replace('&',' ')\n",
    "        tweet = tweet.replace('*',' ')\n",
    "        tweet = tweet.replace('(',' ')\n",
    "        tweet = tweet.replace(')',' ')\n",
    "        tweet = tweet.replace('-',' ')\n",
    "        tweet = tweet.replace('+',' ')\n",
    "        tweet = tweet.replace('=',' ')\n",
    "        tweet = tweet.replace('_',' ')\n",
    "        tweet = tweet.replace('.',' ')\n",
    "        tweet = tweet.replace(':',' ')\n",
    "        tweet = tweet.replace(';',' ')\n",
    "        tweet = tweet.replace('?',' ')\n",
    "        tweet = tweet.replace('/',' ')\n",
    "        tweet = tweet.replace('\\n',' ')\n",
    "        for i in range(0,4): tweet = tweet.replace('  ',' ')\n",
    "        return tweet\n",
    "                              \n",
    "    def show(self):\n",
    "        if self.trained: print(\"Treinado com \" + str(len(self.WordFreqList)) + \" Palavras\")\n",
    "        else: print(\"Precisa ser treinado\")\n",
    "    \n",
    "    def showAll(self):\n",
    "        if self.trained:\n",
    "            print(self.WordFreqList)\n",
    "            print()\n",
    "            print(\"Treinado com \" + str(len(self.WordFreqList)) + \" Palavras\")\n",
    "        else: print(\"Precisa ser treinado\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Classificador = NaiveBayes()\n",
    "Classificador.train(train)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muito Irrelevante Falso: 13.5%\n",
      "Muito Irrelevante Verdadeiro: 2.0%\n",
      "\n",
      "Irrelevante Falso: 16.5%\n",
      "Irrelevante Verdadeiro: 2.5%\n",
      "\n",
      "Meme Falso: 52.5%\n",
      "Meme Verdadeiro: 3.5000000000000004%\n",
      "\n",
      "Relevante Falso: 8.5%\n",
      "Relevante Verdadeiro: 1.0%\n",
      "\n",
      "Muito Relevante Falso: 0.0%\n",
      "Muito Relevante Verdadeiro: 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Acerto: 9.0%\n",
      "Erro: 91.0%\n",
      "\n",
      "\n",
      "\n",
      "Total: 100.0%\n"
     ]
    }
   ],
   "source": [
    "Classificador.test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.[ ]\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.[ ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O nosso Classificador Naive-Bayes analisa propabilidade de um tweet ser relevante, irrelevante ou um meme/piada baseado nas palavras usadas nele. Para conhecer a probalidade de relevancia de uma palavra fornecemos um primeiro grupo de tweet para treina-lo.\n",
    "Tivemos um percentual de analises corretas extremamente baixas, compreendemos o motivo disso atraves de nosso Classificador Naive Bayes de apenas 2 Categorias, que pode ser encontrado no arquivo de apoio no gitHub (ArquivoDeApoio.ipynb), assim como lá o que o classificador fez, foi sempre ter uma chance maior de julgar que um determinado Tweet pertence ao grupo com mais amostras no grupo de treino. No Classificador com apenas 2 Categorias isso não se mostrou tão problematico, já que alem da categoria irrelevante possuir o maior numero de Tweet em relação a outra categoria, ele tambem possuia a maioria dos Tweet da amostra. Porem ao acinonarmos mais categorias a categoria 2(Memes) passa a ser a categoria com maior numero de Tweets em relação as outras categorias, mas não mais a maioria dos Tweets da amostra. Fazendo assim com que a maioria dos Tweets analisados fossem classificados como Memes.\n",
    "\n",
    "Como não existe uma analise completa do tweet, nosso clasificador não reconhece contexto, sarcasmo, duplas negações ou qualquer outro aspecto da frase que não seja a probalidade de suas palavras tornararem o proprio tweet relevante, isso faz com que o classificador cometa diverssos erros, já que podemos usar certas palavras em diversos contextos com divesos significados diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Em nossas proximas iterações, para podermos aprimorar nosso Classificador e sem alterar o tipo dele (Naive-Bayes), vamos por exemplo:\n",
    "    \n",
    "* Aprimorar a qualidade do banco de Treino<br><br />\n",
    "* Ao se deparar com um Tweet, por exemplo: \"Eu gosto de beber Redbull sextas a noite\", alem de analisar e registrar cada uma das palavras nossa classificador passará a analisar tambem fragmentos do tweet, como: \"Eu gosto de\", \"beber Redbull\" e \"sextas a noite\"<br><br />\n",
    "* Passar a não registrar artigos de ligação, como: \"de\", \"do\", \"dos\", \"da\", \"das\", etc.<br><br />\n",
    "* Fornecer ao Classificador um grupo de regras para transformar abreviações em sua versão completa e corrigir erros de escrita, para que dessa forma não registre duas palavras iguais como duas diferentes, tal como: \"vc\" e \"você\", aumentando a qualidade do treinamento e de analise do Classificador.<br><br />\n",
    "* Desenvolver uma tecnica de associação para que as categorias ligadas como: Relevante, Irrelevante, Muito Relevante e Muito Irrelevante, atuem como uma sequencia de uma da outra e baseado em um sistema de pontuação o Classificador possa decidir em qual categoria o Tweet esta<br><br />\n",
    "* Combinar a analise Naive-Bayes com a analise de uma Inteligencia Artificial 100% programada, baseada as regras que nós mesmos utilizamos para classificar os Tweets, tal como: Se não ao menos fala do produto é Muito Irrelevante, se fala do produto mas é um reTweet é Irrelevante mesmo que o Tweet Inicial fosse Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
